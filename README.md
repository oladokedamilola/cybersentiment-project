# ðŸ“Š CyberSentiment

**Social Media Sentiment Analysis for Early Detection of Cybersecurity Threat Trends**

## ðŸŽ¯ Project Aim

The goal of this project is to develop a system that collects cybersecurity-related discussions from social media platforms (Twitter and Reddit), applies sentiment analysis and machine learning techniques, and provides early warning indicators of potential cybersecurity threats.

By leveraging public discourse, the system aims to support **Security Operations Centers (SOCs)** and analysts with **real-time situational awareness**, reducing the risk of undetected emerging threats.

---

## Project Structure

cybersentiment/
â”‚â”€â”€ data/                  # Raw and processed datasets
â”‚   â”œâ”€â”€ raw/               # Original scraped CSV/JSON
â”‚   â”œâ”€â”€ processed/         # Cleaned/preprocessed data
â”‚
â”‚â”€â”€ scripts/               # Data collection + preprocessing scripts
â”‚   â”œâ”€â”€ twitter_scraper.py
â”‚   â”œâ”€â”€ reddit_scraper.py
â”‚   â”œâ”€â”€ preprocess.py
â”‚
â”‚â”€â”€ models/                # ML & DL models (saved .pkl/.h5)
â”‚   â”œâ”€â”€ vader_baseline.pkl (optional for ML/DL only)
â”‚   â”œâ”€â”€ logistic_model.pkl
â”‚   â”œâ”€â”€ cnn_model.h5
â”‚
â”‚â”€â”€ notebooks/             # Jupyter notebooks for experiments
â”‚   â”œâ”€â”€ EDA.ipynb
â”‚   â”œâ”€â”€ model_training.ipynb
â”‚
â”‚â”€â”€ cyber-sentiment/
â”œâ”€â”€ app.py
â”œâ”€â”€ config.py
â”œâ”€â”€ models.py
â”œâ”€â”€ forms.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ instance/
â”‚ â””â”€â”€ config.py # secret keys (ignored by git)
â”œâ”€â”€ static/
â”‚ â”œâ”€â”€ css/
â”‚ â”‚ â””â”€â”€ styles.css
â”‚ â”œâ”€â”€ js/
â”‚ â”‚ â””â”€â”€ main.js
â”‚ â””â”€â”€ vendor/
â”‚ â””â”€â”€ chart.min.js # Chart.js (or use CDN)
â”œâ”€â”€ templates/
â”‚ â”œâ”€â”€ base.html
â”‚ â”œâ”€â”€ index.html
â”‚ â”œâ”€â”€ register.html
â”‚ â”œâ”€â”€ login.html
â”‚ â”œâ”€â”€ dashboard.html
â”‚ â””â”€â”€ alerts.html
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ sentiment_utils.py # model loading + helper functions
â”œâ”€â”€ data/
â”‚ â””â”€â”€ sample_posts.csv # optional sample data
â””â”€â”€ README.md
â”‚
â”‚â”€â”€ tests/                 # Unit tests for scrapers, models, API
â”‚
â”‚â”€â”€ requirements.txt       # Python dependencies
â”‚â”€â”€ README.md              # Project documentation
â”‚â”€â”€ .gitignore             # Ignore venv, data, cache, etc.


## ðŸ§° Tech Stack

**Data Collection**

* Python (Tweepy, PRAW, Requests, Pandas)

**Preprocessing & NLP**

* NLTK, spaCy, Regex, Scikit-learn

**Sentiment & Threat Modeling**

* VADER (lexicon-based baseline)
* Scikit-learn (Logistic Regression, XGBoost with TF-IDF)
* Keras/TensorFlow (CNN, BiLSTM)

**Backend & Model Serving**

* Django (Python web framework)
* Django REST Framework (API layer)
* SQLite / PostgreSQL (database)

**Frontend**

* HTML5, CSS3, Bootstrap 5
* JavaScript (Chart.js / D3.js for visualizations)

**Deployment**

* Docker (containerization)
* Heroku / AWS / Render (cloud hosting)

---

## ðŸ›  Planned Development Roadmap

### **Phase 1: Data Collection (âœ… in progress)**

* Collect data from **Twitter (API v2)** and **Reddit (Pushshift + PRAW)**.
* Store posts with metadata (platform, text, timestamp, sentiment placeholder).
* Run scripts manually (automation to be added later).

### **Phase 2: Data Preprocessing**

* Clean and normalize text (remove URLs, emojis, special characters).
* Tokenization, stopword removal, lemmatization.
* Store processed data separately from raw data.

### **Phase 3: Sentiment & Threat Modeling**

* Implement **VADER** baseline for quick sentiment scoring.
* Train **classical ML model** (Logistic Regression / XGBoost) with TF-IDF.
* Train **lightweight deep learning model** (CNN / BiLSTM).
* Evaluate models on accuracy, precision, recall, and F1-score.

### **Phase 4: Model Integration**

* Build a prediction pipeline (VADER â†’ ML â†’ DL).
* Store results (sentiment & threat classification) in database.

### **Phase 5: Web Application Development**

* Develop a **Django-based web app**.
* Frontend with **HTML, CSS, Bootstrap 5, JavaScript**.
* Features:

  * Dashboard with sentiment trends.
  * Keyword search & filtering.
  * Alerts for high-risk posts.

### **Phase 6: Deployment & Testing**

* Deploy web app on cloud (Heroku / AWS / Render).
* Implement continuous monitoring & periodic retraining.

---

ðŸ“Œ This roadmap will be **updated as development progresses**, with details added for each phase once implemented.

---